dataset:
  name: cifar  # !!!
  batch_size: 64
  resize_size: [256, 256]
  crop_size: [224, 224]
  normalize: imagenet

train:
  epochs: 100
  base_lr_grid: [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]
  modify_lr: False
  lr_decay: False
  weight_decay_grid: [0, 0.0001, 0.001, 0.01]
  optimizer_type: adam
  save_prompt: False

model:
  name: vit
  trainable_para: ['projector', 'opt']
  load_opt: False

  # Source prompt
  src_len: 100
  src_task: 'imdb'
  src_model: roberta
  projection: 'type1'
  inner_dim: 768  # Useless

  # Target prompt (there is no target prompt, all the parameters down here are just to make sure target prompts do not exist)
  tgt_len: 0
  tgt_init: xavier
  tgt_involvement: concat
  cls_pos: after prompt

log:
  dir_lvl_2: ProjectionTransfer